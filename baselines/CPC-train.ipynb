{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of the CPC baseline based on the code available on\n",
    "https://openreview.net/forum?id=8qDwejCuCN\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "os.chdir(\"../\") #Load from parent directory\n",
    "from data_utils import Plots,gen_loader,load_datasets\n",
    "from models import select_encoder\n",
    "utils_plot=Plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(data, encoder, ds_estimator, auto_regressor, device, window_size, n_size, optimizer, train=True):\n",
    "    \n",
    "    if window_size==-1:\n",
    "        window_size = max(2,int(data.shape[-1]/10))\n",
    "        if window_size*10 == data.shape[-1]:\n",
    "            window_size = window_size-1\n",
    "\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        ds_estimator.train()\n",
    "        auto_regressor.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        ds_estimator.eval()\n",
    "        auto_regressor.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    acc = 0\n",
    "    \n",
    "    for sample in data:\n",
    "\n",
    "        rnd_t = np.random.randint(5*window_size,sample.shape[-1]-5*window_size)\n",
    "        sample = torch.Tensor(sample[:,max(0,(rnd_t-20*window_size)):min(sample.shape[-1], rnd_t+20*window_size)])\n",
    "        \n",
    "        T = sample.shape[-1]\n",
    "        windowed_sample = np.split(sample[:, :(T // window_size) * window_size], (T // window_size), -1)\n",
    "        windowed_sample = torch.tensor(np.stack(windowed_sample, 0), device=device)   \n",
    "        encodings = encoder(windowed_sample)\n",
    "\n",
    "        window_ind = torch.randint(2,len(encodings)-2, size=(1,))\n",
    "        \n",
    "        _, c_t = auto_regressor(encodings[max(0, window_ind[0]-10):window_ind[0]+1].unsqueeze(0))\n",
    "        \n",
    "        density_ratios = torch.bmm(encodings.unsqueeze(1),\n",
    "                                   ds_estimator(c_t.squeeze(1).squeeze(0)).expand_as(encodings).unsqueeze(-1)).view(-1,)\n",
    "        \n",
    "        r = set(range(0, window_ind[0] - 2))\n",
    "        r.update(set(range(window_ind[0] + 3, len(encodings))))\n",
    "        rnd_n = np.random.choice(list(r), n_size)\n",
    "        X_N = torch.cat([density_ratios[rnd_n], density_ratios[window_ind[0] + 1].unsqueeze(0)], 0)\n",
    "        \n",
    "        if torch.argmax(X_N)==len(X_N)-1:\n",
    "            acc += 1\n",
    "        labels = torch.Tensor([len(X_N)-1]).to(device)\n",
    "        loss = torch.nn.CrossEntropyLoss()(X_N.view(1, -1), labels.long())\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return epoch_loss / len(data), acc/(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_encoder(n_cross_val,data_type,datasets,lr,window_size,n_size,tr_percentage,\n",
    "                  encoder_type,encoding_size,decay,n_epochs,suffix,device,device_ids,verbose,show_encodings):\n",
    "        \n",
    "    accuracies=[]\n",
    "    for cv in range(n_cross_val):\n",
    "        train_data,train_labels,test_data,test_labels = load_datasets(args['data_type'],args['datasets'],cv)\n",
    "\n",
    "        #Save Location\n",
    "        save_dir = './results/baselines/%s_cpc/%s/'%(datasets,data_type)\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "        save_file = str((save_dir +'encoding_%d_encoder_%d_checkpoint_%d%s.pth.tar')\n",
    "               %(encoding_size,encoder_type, cv,suffix))\n",
    "        \n",
    "        if verbose:\n",
    "            print('Saving at: ',save_file)\n",
    "        \n",
    "        #Models\n",
    "\n",
    "        input_size = train_data.shape[1]\n",
    "        encoder,_ = select_encoder(device,encoder_type,input_size,encoding_size)\n",
    "        ds_estimator = torch.nn.Linear(encoder.encoding_size, encoder.encoding_size).to(device)\n",
    "        auto_regressor = torch.nn.GRU(input_size=encoding_size, hidden_size=encoding_size, batch_first=True).to(device)\n",
    "        \n",
    "        #Training init\n",
    "        params = list(ds_estimator.parameters()) + list(encoder.parameters()) + list(auto_regressor.parameters())\n",
    "        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, n_epochs, gamma=0.999)\n",
    "        \n",
    "        #Split/Shuffle train and val\n",
    "        inds = list(range(len(train_data)))\n",
    "        random.shuffle(inds)\n",
    "        train_data = train_data[inds]\n",
    "        n_train = int(tr_percentage*len(train_data))\n",
    "        best_acc = 0\n",
    "        best_loss = np.inf\n",
    "        train_loss, val_loss = [], []\n",
    "\n",
    "        #Train\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss, acc = epoch_run(train_data[:n_train], encoder, ds_estimator,\n",
    "                                        auto_regressor, device, window_size, n_size, optimizer, train=True)\n",
    "            epoch_loss_val, acc_val = epoch_run(train_data[n_train:], encoder, ds_estimator,\n",
    "                                                auto_regressor, device, window_size, n_size, optimizer, train=False)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if verbose:\n",
    "                print('\\nEpoch ', epoch)\n",
    "                print('Train ===> Loss: ', epoch_loss)\n",
    "                print('Validation ===> Loss: ', epoch_loss_val)\n",
    "            \n",
    "            train_loss.append(epoch_loss)\n",
    "            val_loss.append(epoch_loss_val)\n",
    "            \n",
    "            if epoch_loss_val<best_loss:\n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict()\n",
    "                }\n",
    "                best_acc = acc_val\n",
    "                best_loss = epoch_loss_val\n",
    "                torch.save(state, save_file)\n",
    "                if verbose:\n",
    "                    print('Saving ckpt')\n",
    "                \n",
    "        accuracies.append(best_acc)\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(n_epochs), train_loss, label=\"Train\")\n",
    "        plt.plot(np.arange(n_epochs), val_loss, label=\"Validation\")\n",
    "        plt.title(\"CPC Unsupervised Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_dir +'encoding_%d_encoder_%d_checkpoint_%d%s.png'%(encoding_size,encoder_type, cv,suffix))\n",
    "        if verbose:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        if verbose:\n",
    "            print('Best Train ===> Loss: ', np.min(train_loss))\n",
    "            print('Best Validation ===> Loss: ', np.min(val_loss))\n",
    "            print('-----Accuracy: %.2f +- %.2f-----' % (100 * np.mean(accuracies), 100 * np.std(accuracies)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpc(args):\n",
    "    s_scores=[]\n",
    "    dbi_scores=[]\n",
    "    #Run Process\n",
    "    learn_encoder(**args)\n",
    "    \n",
    "    #Plot Features\n",
    "    title = 'CPC Encoding TSNE for %s'%(args['data_type'])\n",
    "    if args['show_encodings']:\n",
    "        for cv in range(args['n_cross_val']):\n",
    "            train_data,train_labels,test_data,test_labels = load_datasets(args['data_type'],args['datasets'],cv)\n",
    "            utils_plot.plot_distribution(test_data, test_labels,args['encoder_type'],\n",
    "                                         args['encoding_size'],args['window_size'],'cpc',\n",
    "                                         args['datasets'],args['data_type'],args['suffix'],\n",
    "                                         args['device'], title, cv,augment=100) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    #Devices\n",
    "    args['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    args['device_ids'] = [i for i in range(torch.cuda.device_count())]\n",
    "    args['device'] = torch.device(\"cuda:0\")\n",
    "    print('Using', args['device'])\n",
    "\n",
    "    #Experiment Parameters\n",
    "    args['window_size'] = 2500\n",
    "    args['encoder_type'] = 1\n",
    "    args['encoding_size'] = 128\n",
    "    args['lr'] = 1e-4\n",
    "    args['decay'] = 1e-5\n",
    "    args['datasets'] = args['data_type']\n",
    "    args['n_size'] = 4\n",
    "\n",
    "    run_cpc(args)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {'n_cross_val':5,\n",
    "        'data_type':'afdb',  #options: afdb, ims, urban\n",
    "        'tr_percentage':0.8,\n",
    "        'n_epochs':100,\n",
    "        'suffix':'',\n",
    "        'show_encodings':False,\n",
    "        'verbose': True} \n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
