{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score,davies_bouldin_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "os.chdir(\"../\") #Load from parent directory\n",
    "from data_utils import load_datasets\n",
    "from models import select_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters(device,window_size,n_cross_val,data_type,model_type,\n",
    "             encoding_size,encoder_type,suffix,addon=0):\n",
    "    datasets = data_type\n",
    "    if data_type =='afdb':\n",
    "        n_classes  = 4\n",
    "    elif data_type =='ims':\n",
    "        n_classes  = 5\n",
    "    elif data_type =='urban':\n",
    "        n_classes  = 10 \n",
    "    \n",
    "    s_score = []\n",
    "    db_score = []\n",
    "    \n",
    "    for cv in range(n_cross_val):\n",
    "        train_data,train_labels,x_test,y_test = load_datasets(data_type,datasets,cv)\n",
    "        input_size = [x.shape for x in x_test][0][0]\n",
    "        T = x_test.shape[-1]\n",
    "        x_chopped_test = np.split(x_test[:, :, :window_size * (T // window_size)], (T // window_size), -1)\n",
    "        y_chopped_test = np.concatenate(np.split(y_test[:, :window_size * (T // window_size)], (T // window_size), -1),\n",
    "                                           0).astype(int)\n",
    "        x_chopped_test = torch.Tensor(np.concatenate(x_chopped_test, 0))\n",
    "        y_chopped_test = torch.Tensor(np.array([np.bincount(yy).argmax() for yy in y_chopped_test]))\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(x_chopped_test, y_chopped_test)\n",
    "        loader = torch.utils.data.DataLoader(testset, batch_size=100)\n",
    "        \n",
    "        checkpoint = torch.load('./results/baselines/%s_%s/%s/encoding_%d_encoder_%d_checkpoint_%d%s.pth.tar' \n",
    "                            %(datasets,model_type,data_type,encoding_size,encoder_type, cv+addon,suffix))\n",
    "        \n",
    "        encoder,_ = select_encoder(device,encoder_type,input_size,encoding_size)\n",
    "        \n",
    "        encoder = encoder.to(device)\n",
    "        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        encoder.eval()\n",
    "        encodings = []\n",
    "        for windows, _ in loader:\n",
    "            windows = windows.to(device)\n",
    "            encoding = encoder(windows).detach().cpu().numpy()\n",
    "            encodings.append(encoding)\n",
    "        encodings = np.concatenate(encodings, 0)\n",
    "        kmeans = KMeans(n_clusters=n_classes, random_state=1).fit(encodings)\n",
    "        cluster_labels = kmeans.labels_\n",
    "        print(silhouette_score(encodings, cluster_labels),davies_bouldin_score(encodings, cluster_labels))\n",
    "        s_score.append(silhouette_score(encodings, cluster_labels))\n",
    "        db_score.append(davies_bouldin_score(encodings, cluster_labels))\n",
    "        del encodings\n",
    "        \n",
    "    print('Silhouette score: ', np.mean(s_score),'+-', np.std(s_score))\n",
    "    print('Davies Bouldin score: ', np.mean(db_score),'+-', np.std(db_score))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={'n_cross_val' : 10,\n",
    "       'data_type' : 'urban',  #options: afdb, ims, urban\n",
    "       'model_type' : 'tloss', #options: sup, cpc, tloss, tnc, simclr\n",
    "       'encoder_type' : 1,\n",
    "       'window_size' : 2500,\n",
    "       'encoding_size' : 128,\n",
    "       'suffix' : '',\n",
    "       'device' : 'cuda'}\n",
    "\n",
    "clusters(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
