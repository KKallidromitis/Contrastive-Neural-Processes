{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of the TNC baseline based on the code available on\n",
    "https://openreview.net/forum?id=8qDwejCuCN\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "os.chdir(\"../\") #Load from parent directory\n",
    "from data_utils import Plots,gen_loader,load_datasets\n",
    "from models import select_encoder\n",
    "\n",
    "utils_plot=Plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_size, device):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.model = torch.nn.Sequential(torch.nn.Linear(2*self.input_size, 4*self.input_size),\n",
    "                                         torch.nn.ReLU(inplace=True),\n",
    "                                         torch.nn.Dropout(0.5),\n",
    "                                         torch.nn.Linear(4*self.input_size, 1))\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.model[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.model[3].weight)\n",
    "\n",
    "    def forward(self, x, x_tild):\n",
    "        \"\"\"\n",
    "        Predict the probability of the two inputs belonging to the same neighbourhood.\n",
    "        \"\"\"\n",
    "        x_all = torch.cat([x, x_tild], -1)\n",
    "        p = self.model(x_all)\n",
    "        return p.view((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNCDataset(Dataset):\n",
    "    def __init__(self, x, mc_sample_size, window_size, augmentation, epsilon = 3, state=None, adf=False):\n",
    "        super(TNCDataset, self).__init__()\n",
    "        self.time_series = x\n",
    "        self.T = x.shape[-1]\n",
    "        self.window_size = window_size\n",
    "        self.sliding_gap = int(window_size*25.2)\n",
    "        self.window_per_sample = (self.T-2*self.window_size)//self.sliding_gap\n",
    "        self.mc_sample_size = mc_sample_size\n",
    "        self.state = state\n",
    "        self.augmentation = augmentation\n",
    "        self.adf = adf\n",
    "        if not self.adf:\n",
    "            self.epsilon = epsilon\n",
    "            self.delta = 5*window_size*epsilon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series)*self.augmentation\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        ind = ind%len(self.time_series)\n",
    "        t = np.random.randint(2*self.window_size, self.T-2*self.window_size)\n",
    "        x_t = self.time_series[ind][:,t-self.window_size//2:t+self.window_size//2]\n",
    "        X_close = self._find_neighours(self.time_series[ind], t)\n",
    "        X_distant = self._find_non_neighours(self.time_series[ind], t)\n",
    "\n",
    "        if self.state is None:\n",
    "            y_t = -1\n",
    "        else:\n",
    "            y_t = torch.round(torch.mean(self.state[ind][t-self.window_size//2:t+self.window_size//2]))\n",
    "        return x_t, X_close, X_distant, y_t\n",
    "\n",
    "    def _find_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if self.adf:\n",
    "            gap = self.window_size\n",
    "            corr = []\n",
    "            for w_t in range(self.window_size,4*self.window_size, gap):\n",
    "                try:\n",
    "                    p_val = 0\n",
    "                    for f in range(x.shape[-2]):\n",
    "                        p = adfuller(np.array(x[f, max(0,t - w_t):min(x.shape[-1], t + w_t)].reshape(-1, )))[1]\n",
    "                        p_val += 0.01 if math.isnan(p) else p\n",
    "                    corr.append(p_val/x.shape[-2])\n",
    "                except:\n",
    "                    corr.append(0.6)\n",
    "            self.epsilon = len(corr) if len(np.where(np.array(corr) >= 0.01)[0])==0 else (np.where(np.array(corr) >= 0.01)[0][0] +1)\n",
    "            self.delta = 5*self.epsilon*self.window_size\n",
    "\n",
    "        ## Random from a Gaussian\n",
    "        t_p = [int(t+np.random.randn()*self.epsilon*self.window_size) for _ in range(self.mc_sample_size)]\n",
    "        t_p = [max(self.window_size//2+1,min(t_pp,T-self.window_size//2)) for t_pp in t_p]\n",
    "        x_p = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_p])\n",
    "        return x_p\n",
    "\n",
    "    def _find_non_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if t>T/2:\n",
    "            t_n = np.random.randint(min(self.window_size//2+1, t - self.delta), (t - self.delta + 1), self.mc_sample_size)\n",
    "        else:\n",
    "            t_n = np.random.randint(min((t + self.delta), (T - self.window_size-1)), (T - self.window_size//2), self.mc_sample_size)\n",
    "        x_n = torch.stack([x[:, t_ind-self.window_size//2:t_ind+self.window_size//2] for t_ind in t_n])\n",
    "        return x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(loader, disc_model, encoder, device, w=0, optimizer=None, train=True):\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        disc_model.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        disc_model.eval()\n",
    "    # loss_fn = torch.nn.BCELoss()\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    encoder.to(device)\n",
    "    disc_model.to(device)\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    batch_count = 0\n",
    "    for x_t, x_p, x_n, _ in loader:\n",
    "        mc_sample = x_p.shape[1]\n",
    "        batch_size, f_size, len_size = x_t.shape\n",
    "        x_p = x_p.reshape((-1, f_size, len_size))\n",
    "        x_n = x_n.reshape((-1, f_size, len_size))\n",
    "        x_t = np.repeat(x_t, mc_sample, axis=0)\n",
    "        neighbors = torch.ones((len(x_p))).to(device)\n",
    "        non_neighbors = torch.zeros((len(x_n))).to(device)\n",
    "        x_t, x_p, x_n = x_t.to(device), x_p.to(device), x_n.to(device)\n",
    "\n",
    "        z_t = encoder(x_t)\n",
    "        z_p = encoder(x_p)\n",
    "        z_n = encoder(x_n)\n",
    "\n",
    "        d_p = disc_model(z_t, z_p)\n",
    "        d_n = disc_model(z_t, z_n)\n",
    "\n",
    "        p_loss = loss_fn(d_p, neighbors)\n",
    "        n_loss = loss_fn(d_n, non_neighbors)\n",
    "        n_loss_u = loss_fn(d_n, neighbors)\n",
    "        loss = (p_loss + w*n_loss_u + (1-w)*n_loss)/2\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        p_acc = torch.sum(torch.nn.Sigmoid()(d_p) > 0.5).item() / len(z_p)\n",
    "        n_acc = torch.sum(torch.nn.Sigmoid()(d_n) < 0.5).item() / len(z_n)\n",
    "        epoch_acc = epoch_acc + (p_acc+n_acc)/2\n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    return epoch_loss/batch_count, epoch_acc/batch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_encoder(n_cross_val,data_type,tr_percentage,n_epochs,suffix,show_encodings,verbose,device,device_ids,batch_size,\n",
    "                  window_size,encoder_type,encoding_size,lr,decay,datasets,w,mc_sample_size,augmentation):\n",
    "\n",
    "    accuracies, losses = [], []\n",
    "    \n",
    "    for cv in range(n_cross_val):\n",
    "        train_data,train_labels,test_data,test_labels = load_datasets(data_type,datasets,cv)\n",
    "        #Save Location\n",
    "        save_dir = './results/baselines/%s_tnc/%s/'%(datasets,data_type)\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "        save_file = str((save_dir +'encoding_%d_encoder_%d_checkpoint_%d%s.pth.tar')\n",
    "               %(encoding_size,encoder_type, cv,suffix))\n",
    "        \n",
    "        input_size = train_data.shape[1]\n",
    "        encoder,_ = select_encoder(device,encoder_type,input_size,encoding_size)\n",
    "        encoder = encoder.to(device)\n",
    "        \n",
    "        disc_model = Discriminator(encoder.encoding_size, device)\n",
    "        params = list(disc_model.parameters()) + list(encoder.parameters())\n",
    "        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, n_epochs, gamma=0.999)\n",
    "        inds = list(range(len(train_data)))\n",
    "        random.shuffle(inds)\n",
    "        train_data = train_data[inds]\n",
    "        n_train = int(tr_percentage*len(train_data))\n",
    "        performance = []\n",
    "        best_acc = 0\n",
    "        best_loss = np.inf\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            trainset = TNCDataset(torch.Tensor(train_data[:n_train]), mc_sample_size=mc_sample_size,\n",
    "                                  window_size=window_size, augmentation=augmentation, adf=True)\n",
    "            train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "            \n",
    "            validset = TNCDataset(torch.Tensor(train_data[n_train:]), mc_sample_size=mc_sample_size, adf=True,\n",
    "                                  window_size=window_size, augmentation=augmentation)\n",
    "\n",
    "            valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            epoch_loss, epoch_acc = epoch_run(train_loader, disc_model, encoder, optimizer=optimizer,\n",
    "                                              w=w, train=True, device=device)\n",
    "\n",
    "            val_loss, val_acc = epoch_run(valid_loader, disc_model, encoder, train=False, w=w, device=device)\n",
    "            performance.append((epoch_loss, val_loss, epoch_acc, val_acc))\n",
    "            scheduler.step()\n",
    "            \n",
    "            if verbose:\n",
    "                print('\\nEpoch ', epoch)\n",
    "                print('Train ===> Loss: ', epoch_loss)\n",
    "                print('Validation ===> Loss: ', val_loss)\n",
    "                \n",
    "            if best_loss > val_loss:\n",
    "                best_acc = val_acc\n",
    "                best_loss = val_loss\n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'discriminator_state_dict': disc_model.state_dict(),\n",
    "                    'best_accuracy': val_acc\n",
    "                }\n",
    "                torch.save(state, save_file)\n",
    "                if verbose:\n",
    "                    print('Saving ckpt')\n",
    "                \n",
    "        accuracies.append(best_acc)\n",
    "        losses.append(best_loss)\n",
    "        \n",
    "        # Save performance plots\n",
    "            \n",
    "        train_loss = [t[0] for t in performance]\n",
    "        val_loss = [t[1] for t in performance]\n",
    "        train_acc = [t[2] for t in performance]\n",
    "        val_acc = [t[3] for t in performance]\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(n_epochs), train_loss, label=\"Train\")\n",
    "        plt.plot(np.arange(n_epochs), val_loss, label=\"Validation\")\n",
    "        plt.title(\"TNC Unsupervised Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_dir +'encoding_%d_encoder_%d_checkpoint_%d%s_loss.png'%(encoding_size,encoder_type, cv,suffix))\n",
    "        if verbose:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(n_epochs), train_acc, label=\"Train\")\n",
    "        plt.plot(np.arange(n_epochs), val_acc, label=\"Validation\")\n",
    "        plt.title(\"TNC Unsupervised Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.savefig(save_dir +'encoding_%d_encoder_%d_checkpoint_%d%s_acc.png'%(encoding_size,encoder_type, cv,suffix))\n",
    "\n",
    "        if verbose:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    if verbose:\n",
    "        print('=======> Performance Summary:')\n",
    "        print('Accuracy: %.2f +- %.2f'%(100*np.mean(accuracies), 100*np.std(accuracies)))\n",
    "        print('Loss: %.4f +- %.4f'%(np.mean(losses), np.std(losses)))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tnc(args):\n",
    "\n",
    "    #Run Process\n",
    "    learn_encoder(**args)\n",
    "    \n",
    "    #Plot Features\n",
    "    title = 'TNC Encoding TSNE for %s'%(args['data_type'])\n",
    "    \n",
    "    if args['show_encodings']:\n",
    "        for cv in range(args['n_cross_val']):\n",
    "            _,_,test_data,test_labels = load_datasets(args['data_type'],args['datasets'],cv)\n",
    "            utils_plot.plot_distribution(test_data, test_labels,args['encoder_type'],\n",
    "                                                             args['encoding_size'],args['window_size'],'tnc',\n",
    "                                                             args['datasets'],args['data_type'],args['suffix'],\n",
    "                                                             args['device'], title, cv)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    #Devices\n",
    "    args['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    args['device_ids'] = [i for i in range(torch.cuda.device_count())]\n",
    "    print('Using', args['device'])\n",
    "\n",
    "    #Experiments\n",
    "    \n",
    "    if args['data_type']=='afdb':\n",
    "        args['lr'] = 1e-3\n",
    "        args['w'] = .05\n",
    "    if args['data_type']=='ims':\n",
    "        args['lr'] = 1e-4\n",
    "        args['w'] = .1\n",
    "    if args['data_type']=='urban':\n",
    "        args['n_cross_val'] = 10\n",
    "        args['lr'] = 1e-4\n",
    "        args['w'] = .05\n",
    "        \n",
    "    #Experiment Parameters\n",
    "    args['window_size'] = 2500\n",
    "    args['encoder_type'] = 1\n",
    "    args['encoding_size'] = 128\n",
    "    args['decay'] = 1e-5\n",
    "    args['datasets'] = args['data_type']\n",
    "    args['mc_sample_size'] = 10\n",
    "    args['augmentation'] = 7\n",
    "    run_tnc(args)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {'n_cross_val':5,\n",
    "        'data_type':'afdb', #options: afdb, ims, urban\n",
    "        'tr_percentage':0.8,\n",
    "        'n_epochs':100,\n",
    "        'batch_size':8,\n",
    "        'suffix':'',\n",
    "        'show_encodings':False,\n",
    "        'verbose': True} \n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
