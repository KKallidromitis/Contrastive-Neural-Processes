{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of our Contrastive Neural Process approach\n",
    "Resources for neural processes are from: https://github.com/YannDubs/Neural-Process-Family\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import matplotlib\n",
    "os.chdir(\"../\") #Load from parent directory\n",
    "from data_utils import gen_loader,load_datasets,split_series\n",
    "from sklearn.metrics import roc_auc_score,balanced_accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score,davies_bouldin_score\n",
    "from models import select_encoder\n",
    "import pickle\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npf import ConvCNP,CNP\n",
    "from functools import partial\n",
    "from utils.helpers import count_parameters,set_seed\n",
    "from npf.architectures import CNN, MLP, ResConvBlock, SetConv, discard_ith_arg,merge_flat_input\n",
    "from npf.utils.datasplit import GridCntxtTrgtGetter,RandomMasker,no_masker\n",
    "from utils.data import cntxt_trgt_collate\n",
    "\n",
    "\n",
    "def define_model(device,encoder_type,input_size,encoding_size,range_indcs,density_induced=64,is_contrastive=True):\n",
    "    get_cntxt_trgt = cntxt_trgt_collate(GridCntxtTrgtGetter(context_masker=partial(RandomMasker(\n",
    "        a=0.0, b=0.6,range_indcs=range_indcs),is_range=False), target_masker=no_masker),\n",
    "                                           is_duplicate_batch=is_contrastive)          \n",
    "    KWARGS = dict(\n",
    "    XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=encoding_size),\n",
    "    Decoder=merge_flat_input(  # MLP takes single input but we give x and R so merge them\n",
    "        partial(MLP, n_hidden_layers=4, hidden_size=encoding_size), is_sum_merge=True,\n",
    "    ),\n",
    "    r_dim=encoding_size,)\n",
    "    \n",
    "    model = partial(\n",
    "    CNP,\n",
    "    x_dim=1,\n",
    "    y_dim=input_size,\n",
    "    is_contrastive=is_contrastive,\n",
    "    XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "        partial(MLP, n_hidden_layers=2, hidden_size=encoding_size * 2), is_sum_merge=True,\n",
    "    ),\n",
    "    **KWARGS,)\n",
    "\n",
    "    print(f\"Number Parameters (1D): {count_parameters(model()):,d}\")\n",
    "    return model,get_cntxt_trgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skorch\n",
    "from npf.utils.predict import SamplePredictor\n",
    "from npf import Contrastive_CNPFLoss,CNPFLoss\n",
    "from utils.ntbks_helpers import add_y_dim\n",
    "from utils.train import train_models\n",
    "import pandas as pd\n",
    "\n",
    "def train(device,get_cntxt_trgt,trainset,testset,lr,decay,data_type,datasets,batch_size,model,\n",
    "          epochs,is_retrain=True,is_contrastive=True):\n",
    "    \n",
    "    save_dir = \"results/pretrained/%s/\"%(datasets)\n",
    "    if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "    print('Saving at: ',save_dir)\n",
    "            \n",
    "    KWARGS = dict(is_retrain=is_retrain,criterion=partial(\n",
    "        Contrastive_CNPFLoss,is_contrastive=is_contrastive, device=device, batch_size=batch_size,lreg=0.001),\n",
    "                  chckpnt_dirname=save_dir,device=device, lr=lr, decay_lr=decay,\n",
    "                  seed=123,batch_size=batch_size)\n",
    "\n",
    "    trainers = train_models(\n",
    "        {data_type:trainset},\n",
    "        {\"ContrCNP_%s\"%(data_type): model},\n",
    "        train_split=skorch.dataset.CVSplit(0.2),\n",
    "        test_datasets={data_type:testset},\n",
    "        iterator_train__collate_fn=get_cntxt_trgt,\n",
    "        iterator_valid__collate_fn=get_cntxt_trgt,\n",
    "        max_epochs=epochs,\n",
    "        **KWARGS)\n",
    "\n",
    "    return trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range(data_len,trainset):\n",
    "\n",
    "    if data_len != 'Vary':\n",
    "        \n",
    "        num = int(data_len)//100\n",
    "\n",
    "        a = num+1\n",
    "        b = int(data_len)-num-1\n",
    "    else:\n",
    "        min_len = np.inf\n",
    "        for x,y in trainset:\n",
    "            min_len = min(min_len,x.shape[1])\n",
    "\n",
    "        data_len = min_len\n",
    "        num = int(data_len)//100\n",
    "\n",
    "        a = num+1\n",
    "        b = int(data_len)-num-1\n",
    "        \n",
    "    s = int(data_len)//5\n",
    "\n",
    "    return [a,b],s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior_samples(data,data_len,model,is_uniform_grid=False,img_indcs=None,n_plots=4,seed=123,\n",
    "                          n_samples=1,is_select_different=False,n_cntxt=100):\n",
    "    upscale_factor=1\n",
    "    print('Using %s Points'%(n_cntxt))\n",
    "    get_cntxt_trgt = GridCntxtTrgtGetter(\n",
    "            context_masker=RandomMasker(a=n_cntxt, b=n_cntxt),\n",
    "            target_masker=no_masker,\n",
    "            is_add_cntxts_to_trgts=False,\n",
    "            upscale_factor=upscale_factor,\n",
    "        )\n",
    "    set_seed(seed)\n",
    "    model.eval()\n",
    "\n",
    "    if img_indcs is None:\n",
    "        img_indcs = [random.randint(0, len(data) - 1) for _ in range(n_plots)]\n",
    "    n_plots = len(img_indcs)\n",
    "\n",
    "    imgs = [data[i] for i in img_indcs]\n",
    "\n",
    "    cntxt_trgt = cntxt_trgt_collate(\n",
    "        get_cntxt_trgt, is_return_masks=is_uniform_grid\n",
    "    )(imgs)[0]\n",
    "\n",
    "    mask_cntxt, Y_cntxt, mask_trgt, Y_trgt = (\n",
    "        cntxt_trgt[\"X_cntxt\"],\n",
    "        cntxt_trgt[\"Y_cntxt\"],\n",
    "        cntxt_trgt[\"X_trgt\"],\n",
    "        cntxt_trgt[\"Y_trgt\"],\n",
    "    )\n",
    "    print(mask_cntxt.shape, Y_cntxt.shape, mask_trgt.shape)\n",
    "    y_pred = SamplePredictor(model.to('cuda'), is_dist=True)(mask_cntxt.to('cuda'), Y_cntxt.to('cuda'), mask_trgt.to('cuda'))\n",
    "    #print(y_pred)\n",
    "    if is_select_different:\n",
    "        # select the most different in average pixel L2 distance\n",
    "        keep_most_different_samples_(y_pred, n_samples)\n",
    "        \n",
    "    elif isinstance(n_samples, int):\n",
    "        # select first n_samples\n",
    "        y_pred.base_dist.loc = y_pred.base_dist.loc[:n_samples, ...]\n",
    "        y_pred.base_dist.scale = y_pred.base_dist.scale[:n_samples, ...]\n",
    "    elif n_samples is None:\n",
    "        pass  # select all\n",
    "    else:\n",
    "        ValueError(f\"Unkown n_samples={n_samples}.\")\n",
    "        \n",
    "    ids = (mask_cntxt[0]+1)*data_len/2\n",
    "    ids=ids.int()\n",
    "    mean_ys = y_pred.sample_n(n_samples)[:, 0, ...]\n",
    "    mean_y = mean_ys[0]\n",
    "    print(Y_cntxt.shape)\n",
    "\n",
    "    figure, ax = plt.subplots(2,1)\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(8, 5)\n",
    "    \n",
    "    ax[0].plot(mean_y.to('cpu').numpy()[0,:,0])\n",
    "    ax[0].scatter(ids,Y_cntxt[0,:,0],color='r')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    ax[1].set_ylabel('Amplitude')\n",
    "    ax[1].plot(Y_trgt[0,:,0])\n",
    "    ax[1].scatter(ids,Y_cntxt[0,:,0],color='r')\n",
    "    ax[1].set_xlabel('Number of points')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    save={}\n",
    "    save['mean_y']=mean_y\n",
    "    save['ids']=ids\n",
    "    save['Y_cntxt']=Y_cntxt\n",
    "    save['Y_trgt']=Y_trgt\n",
    "    return save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from torchvision import datasets\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score,davies_bouldin_score\n",
    "\n",
    "def plot_enc(x_test,y_test,encoding_size,test_labels,batch_size,device,enc_model,n_cntxt,\n",
    "             upscale_factor,get_cntxt_trgt,window_size=2500,augment=100):\n",
    "    \n",
    "    n_test = len(x_test)\n",
    "    inds = np.random.randint(0, x_test.shape[-1] - window_size, n_test * augment)\n",
    "    windows = np.array([x_test[int(i % n_test), :, ind:ind + window_size] for i, ind in enumerate(inds)])\n",
    "    windows_state = [np.round(np.mean(y_test[i % n_test, ind:ind + window_size], axis=-1)) for i, ind in\n",
    "                    enumerate(inds)]\n",
    "    \n",
    "    testset = torch.utils.data.TensorDataset(torch.Tensor(windows).to(device),torch.Tensor(windows_state).to(device))\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "    encodings = torch.empty(0,encoding_size)\n",
    "\n",
    "    windows_state=[]\n",
    "    for x,y in test_loader:\n",
    "        windows_state.extend(y)\n",
    "\n",
    "        temp = [(x[i].to('cuda'),y[i].to('cuda')) for i in range(batch_size)]\n",
    "        encodings = torch.cat((encodings.to('cuda'),get_encodings('cuda',temp,enc_model.to('cuda'),get_cntxt_trgt).to('cuda')))\n",
    "        encodings = encodings.clone().detach()\n",
    "    tsne = TSNE(n_components=2)\n",
    "        \n",
    "    windows_state = torch.tensor(windows_state)    \n",
    "    print(encodings.shape,windows_state.shape)\n",
    "    embedding = tsne.fit_transform(encodings.detach().cpu().numpy())\n",
    "    df_encoding = pd.DataFrame({\"f1\": embedding[:, 0], \"f2\": embedding[:, 1], \"state\": windows_state})\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.set_style(\"white\")\n",
    "    sns.scatterplot(x=\"f1\", y=\"f2\", data=df_encoding, hue=\"state\", palette=\"deep\")\n",
    "    plt.show()\n",
    "    return encodings,windows_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters(x_test,y_test,enc_model,device,window_size,n_cv,datasets,data_type,encoding_size,\n",
    "             encoder_type,suffix,get_cntxt_trgt,n_classes,batch_size = 8):\n",
    "    \n",
    "    input_size = [x.shape for x in x_test][0][0]\n",
    "    T = x_test.shape[-1]\n",
    "    x_chopped_test = np.split(x_test[:, :, :window_size * (T // window_size)], (T // window_size), -1)\n",
    "    y_chopped_test = np.concatenate(np.split(y_test[:, :window_size * (T // window_size)], (T // window_size), -1),0).astype(int)\n",
    "    x_chopped_test = torch.Tensor(np.concatenate(x_chopped_test, 0))\n",
    "    y_chopped_test = torch.Tensor(np.array([np.bincount(yy).argmax() for yy in y_chopped_test]))\n",
    "    \n",
    "    testset = torch.utils.data.TensorDataset(x_chopped_test, y_chopped_test)\n",
    "    loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False,drop_last=True)\n",
    "\n",
    "    s_score = []\n",
    "    db_score = []\n",
    "    for cv in range(n_cv):\n",
    "        encodings = torch.empty(0,encoding_size)\n",
    "\n",
    "        windows_state=[]\n",
    "        for x,y in loader:\n",
    "\n",
    "            temp = [(x[i].to('cuda'),y[i].to('cuda')) for i in range(batch_size)]\n",
    "            encodings = torch.cat((encodings.to('cuda'),get_encodings('cuda',temp,enc_model.to('cuda'),get_cntxt_trgt).to('cuda')))\n",
    "            encodings = encodings.clone().detach()\n",
    "        encodings=encodings.to('cpu').numpy()\n",
    "            \n",
    "        kmeans = KMeans(n_clusters=n_classes, random_state=1).fit(encodings)\n",
    "        cluster_labels = kmeans.labels_\n",
    "        print(silhouette_score(encodings, cluster_labels),davies_bouldin_score(encodings, cluster_labels))\n",
    "        s_score.append(silhouette_score(encodings, cluster_labels))\n",
    "        db_score.append(davies_bouldin_score(encodings, cluster_labels))\n",
    "        del encodings\n",
    "        \n",
    "    print('Silhouette score: ', np.mean(s_score),'+-', np.std(s_score))\n",
    "    print('Davies Bouldin score: ', np.mean(db_score),'+-', np.std(db_score))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup_train(batch_size,window_size,data_type,device,enc_model,encoder_type,datasets,\n",
    "              encoding_size,lr,n_epochs,tr_percentage,n_classes,get_cntxt_trgt,classifier_type,cv):\n",
    "    \n",
    "    train_data,train_labels,test_data,test_labels = load_datasets(data_type,datasets,cv)\n",
    "    \n",
    "    if data_type in ['afdb','ims','urban']:\n",
    "        train_data,train_labels = split_series(train_data,train_labels,window_size)\n",
    "        test_data,test_labels = split_series(test_data,test_labels,window_size)\n",
    "    \n",
    "    tr = int(tr_percentage*len(train_data))\n",
    "    print(train_data.shape)\n",
    "    trainset=torch.utils.data.TensorDataset(train_data[:tr],train_labels[:tr])\n",
    "    valset = torch.utils.data.TensorDataset(train_data[tr:],train_labels[tr:])\n",
    "    testset=torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "    val_loader=torch.utils.data.DataLoader(valset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "    \n",
    "    input_size = [x.shape for (x,y) in train_loader][0][1]\n",
    "    _,classifier = select_encoder(device,encoder_type,input_size,encoding_size,n_classes,classifier_type)  \n",
    "    classifier=classifier.to(device)\n",
    "    enc_model=enc_model.to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    params = classifier.parameters()\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, n_epochs, gamma=0.99)\n",
    "    best_acc = 0 \n",
    "    \n",
    "    for e in range(n_epochs):  \n",
    "        enc_model.eval()\n",
    "        classifier.train()\n",
    "        epoch_acc = 0\n",
    "        batch_count = 0\n",
    "        epoch_loss = 0\n",
    "        for x,y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            temp = [(x[i],y[i]) for i in range(batch_size)]\n",
    "            encodings = get_encodings(device,temp,enc_model,get_cntxt_trgt)\n",
    "            prediction = classifier(encodings.detach())\n",
    "            state_prediction = torch.argmax(prediction, dim=1)\n",
    "            loss = loss_fn(prediction, y.long().to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_acc += torch.eq(state_prediction.to('cpu'), y).sum().item()/len(x)\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(' Epoch ',e,'Train Labels',tr_percentage)\n",
    "        train_loss,train_acc = epoch_loss / batch_count, epoch_acc / batch_count\n",
    "        print('Train Results: ',train_loss,train_acc)\n",
    "        \n",
    "        val_loss,val_acc,_ = test_supervised(enc_model,classifier,device,val_loader,get_cntxt_trgt,batch_size)\n",
    "        print('Val Results: ',val_loss,val_acc)\n",
    "        \n",
    "        \n",
    "        test_loss,test_acc,test_auc = test_supervised(enc_model,classifier,device,test_loader,get_cntxt_trgt,batch_size,calc_auc=True)\n",
    "        print('Test Results: ',test_loss,test_acc,test_auc)\n",
    "        \n",
    "        \n",
    "    return best_acc\n",
    "\n",
    "def test_supervised(enc_model,classifier,device,data_loader,get_cntxt_trgt,batch_size,calc_auc=False):\n",
    "    enc_model.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_auc = 0\n",
    "    batch_count = 0\n",
    "    y_all, prediction_all = [], []\n",
    "    \n",
    "    for x, y in data_loader:\n",
    "        temp = [(x[i],y[i]) for i in range(batch_size)]\n",
    "        encodings = get_encodings(device,temp,enc_model,get_cntxt_trgt)\n",
    "\n",
    "        prediction = classifier(encodings.detach())\n",
    "        \n",
    "        state_prediction = torch.argmax(prediction, -1)\n",
    "        loss = loss_fn(prediction, y.long().to(device))\n",
    "\n",
    "        epoch_acc += torch.eq(state_prediction.to('cpu'), y).sum().item()/len(x)\n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        y_all.append(y)\n",
    "        prediction_all.append(prediction.detach().cpu().numpy())\n",
    "\n",
    "    if calc_auc:\n",
    "        y_all = np.concatenate(y_all, 0)\n",
    "        prediction_all = np.concatenate(prediction_all, 0)\n",
    "\n",
    "        prediction_class_all = np.argmax(prediction_all, -1)\n",
    "        y_onehot_all = np.zeros(prediction_all.shape)\n",
    "        y_onehot_all[np.arange(len(y_onehot_all)), y_all.astype(int)] = 1\n",
    "        epoch_auc = roc_auc_score(y_onehot_all,prediction_all,multi_class='ovo')\n",
    "\n",
    "    return epoch_loss / batch_count, epoch_acc / batch_count , epoch_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contrnp(n_cross_val,data_type,tr_percentage,val_percentage,n_epochs,ablation,classifier_type,\n",
    "               batch_size,suffix,verbose,show_encodings,device,device_ids,window_size,encoder_type,\n",
    "               encoding_size,lr,decay,datasets,n_classes,is_retrain):\n",
    "    \n",
    "    for cv in range(n_cross_val):\n",
    "        train_data,train_labels,test_data,test_labels = load_datasets(data_type,datasets,cv)\n",
    "        test_data_init = test_data\n",
    "        test_labels_init = test_labels\n",
    "\n",
    "        if batch_size<1:\n",
    "            batch_size = max(1,int(min(len(train_data),len(test_data))*batch_size))\n",
    "            print('Using batch_size:', batch_size)\n",
    "\n",
    "        if data_type in ['afdb','ims','urban']:\n",
    "            train_data,train_labels = split_series(train_data,train_labels,window_size)\n",
    "            test_data,test_labels = split_series(test_data,test_labels,window_size)\n",
    "\n",
    "        trainset=torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "        testset=torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "        data_len = train_data.shape[2]\n",
    "        input_size = train_data.shape[1]\n",
    "    \n",
    "        range_indcs,n_cntxt = find_range(train_data.shape[2],trainset)\n",
    "        print(range_indcs,n_cntxt)\n",
    "        \n",
    "        model,get_cntxt_trgt = define_model(device,encoder_type,input_size,encoding_size,range_indcs)\n",
    "        trainers = train(device,get_cntxt_trgt,trainset,testset,lr,decay,data_type,datasets,batch_size,model,n_epochs,\n",
    "                        is_retrain=is_retrain)\n",
    "        #print(trainers)\n",
    "        trained_model = trainers[\"%s/ContrCNP_%s/run_0\"%(data_type,data_type)].module_.cpu()\n",
    "\n",
    "\n",
    "        upscale_factor=1\n",
    "        save = get_posterior_samples(testset,data_len,trained_model,n_cntxt=n_cntxt)\n",
    "        get_cntxt_trgt = GridCntxtTrgtGetter(\n",
    "                context_masker=RandomMasker(a=n_cntxt, b=n_cntxt),\n",
    "                target_masker=no_masker,\n",
    "                is_add_cntxts_to_trgts=False,\n",
    "                upscale_factor=upscale_factor,\n",
    "            )\n",
    "        if show_encodings:\n",
    "            encodings,windows_state = plot_enc(test_data_init,test_labels_init,encoding_size,test_labels,batch_size,device,trained_model,n_cntxt,upscale_factor,get_cntxt_trgt)\n",
    "\n",
    "        clusters(test_data_init,test_labels_init,trained_model,device,window_size,1,datasets,data_type,\n",
    "                 encoding_size,encoder_type,suffix,get_cntxt_trgt,n_classes)\n",
    "\n",
    "        acc = sup_train(batch_size,window_size,data_type,device,trained_model,encoder_type,datasets,\n",
    "                      encoding_size,lr,n_epochs,tr_percentage,n_classes,get_cntxt_trgt,classifier_type,cv)\n",
    "\n",
    "        print(acc)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encodings(device,data,enc_model,get_cntxt_trgt):\n",
    "\n",
    "    enc_model.eval()\n",
    "    \n",
    "    cntxt_trgt = cntxt_trgt_collate(\n",
    "        get_cntxt_trgt,is_duplicate_batch=False, is_return_masks=False)(data)[0]\n",
    "\n",
    "    X_cntxt, Y_cntxt, X_trgt, Y_trgt = (\n",
    "        cntxt_trgt[\"X_cntxt\"],\n",
    "        cntxt_trgt[\"Y_cntxt\"],\n",
    "        cntxt_trgt[\"X_trgt\"],\n",
    "        cntxt_trgt[\"Y_trgt\"],\n",
    "    )\n",
    "    \n",
    "    X_cntxt, Y_cntxt, X_trgt, Y_trgt = X_cntxt.to(device), Y_cntxt.to(device), X_trgt.to(device), Y_trgt.to(device)\n",
    "    #print(X_cntxt.shape, Y_cntxt.shape, X_trgt.shape)\n",
    "    encodings = SamplePredictor(enc_model,is_enc=True)(X_cntxt, Y_cntxt, X_trgt,Y_trgt,True)\n",
    "    \n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    #Devices\n",
    "    args['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    args['device_ids'] = [i for i in range(torch.cuda.device_count())]\n",
    "    print('Using', args['device'])\n",
    "\n",
    "    #Experiments\n",
    "    if args['data_type']=='afdb' or args['data_type'] == 'ims' or args['data_type'] == 'urban':\n",
    "        \n",
    "        #Experiment Parameters\n",
    "        args['window_size'] = 2500\n",
    "        args['encoder_type'] = 1\n",
    "        args['encoding_size'] = 128\n",
    "        args['lr'] = 1e-3\n",
    "        args['decay'] = 10\n",
    "        args['datasets'] = args['data_type']\n",
    "        \n",
    "        if args['data_type'] == 'afdb':\n",
    "            args['n_classes'] = 4\n",
    "        elif args['data_type'] == 'ims':\n",
    "            args['n_classes'] = 5\n",
    "        elif args['data_type'] == 'urban':\n",
    "            args['n_cross_val'] = 10\n",
    "            args['n_classes'] = 10\n",
    "            \n",
    "        if args['ablation'] == False:\n",
    "            run_contrnp(**args)\n",
    "            \n",
    "        else:\n",
    "            train_accs_dict,train_losses_dict = {},{}\n",
    "            test_accs_dict,test_losses_dict = {},{}\n",
    "            val_accs_dict,val_losses_dict = {},{}\n",
    "            args['show_encodings'] = False\n",
    "            tr = [0.01,0.1,0.2,0.3,0.5,0.7,0.8]\n",
    "            \n",
    "            for train_per in tr:\n",
    "                args['tr_percentage']= train_per\n",
    "                results = run_contrnp(**args)\n",
    "                \n",
    "                train_accs_dict[train_per] = results['train_accs']\n",
    "                train_losses_dict[train_per] = results['train_losses']\n",
    "                test_accs_dict[train_per] = results['test_accs']\n",
    "                test_losses_dict[train_per] = results['test_losses']\n",
    "                val_accs_dict[train_per] = results['val_accs']\n",
    "                val_losses_dict[train_per] = results['val_losses']\n",
    "                \n",
    "                results['train_accs_dict'] = train_accs_dict\n",
    "                results['train_losses_dict'] = train_losses_dict\n",
    "                results['test_accs_dict'] = test_accs_dict\n",
    "                results['test_losses_dict'] = test_losses_dict\n",
    "                results['val_accs_dict'] = val_accs_dict\n",
    "                results['val_losses_dict'] = val_losses_dict\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {'n_cross_val':5,\n",
    "        'data_type':'afdb',\n",
    "        'tr_percentage':0.8,\n",
    "        'val_percentage': 0.2,\n",
    "        'n_epochs':100,\n",
    "        'ablation': False,\n",
    "        'classifier_type':0,\n",
    "        'batch_size': 8,\n",
    "        'suffix':'',\n",
    "        'verbose':True,\n",
    "        'show_encodings': False,\n",
    "        'is_retrain':False} \n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
